{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from collections import Counter \n",
    "import re \n",
    "from shutil import copyfile \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction import text \n",
    "import pandas as pd \n",
    "import html\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import spacy\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['humanitarian', 'humanitarianism']\n",
    "covid_tokens = ['covid','covid19', 'coronavirus', 'virus','lockdown', 'isolate']\n",
    "covid_token2 = ['covid','covid19', 'coronavirus', 'virus']\n",
    "\n",
    "root = 'Raw text/'\n",
    "years = ['2019','2020']\n",
    "year_month = ['201912','202001','202002','202003','202004','202005','202006','202007','202008',]\n",
    "countries = ['CN','IR','QA','RU','TR','US','UK','DE','FR','AE','SA','KW']\n",
    "patterns = [\n",
    "   (r'won\\'t', 'will not'),\n",
    "   (r'can\\'t', 'cannot'),\n",
    "   (r'i\\'m', 'i am'),\n",
    "   (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "   (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "   (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "   (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "   (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Cleaning/Normalization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWords(text, patterns, wordsToCount):\n",
    "    text = text.lower() # Text normalization: make string lowercase\n",
    "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text, flags=re.MULTILINE) #Remove URLs\n",
    "    text = html.unescape(text)   #Remove HTML tags\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "    for (pattern, repl) in patterns:\n",
    "        text = re.sub(pattern, repl, text)    #Replace contractions\n",
    "    text = re.sub(r'[^\\w\\s]','', text) # Text normalization: remove punctuation\n",
    "    \n",
    "    splitString = text.split() # Split string into array of words\n",
    "    counts = Counter(splitString) # Get counts for each word like Counter({'dogs': 3, 'cute': 1})\n",
    "    count = 0 # Start the counter\n",
    "    for word in wordsToCount: # Loop through list of words and add the count\n",
    "        count = count + counts[word]\n",
    "        print()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting covid relevant articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanOnWordCount(country, tokens, covid_tokens, root, patterns, year_month):\n",
    "    print(\"Processing\", country, \"...\")\n",
    "    # Directory declarations\n",
    "    myCorpusRoot = str(root) + str(country)\n",
    "    myCorpusRootClean = str(root) + str(country) + 'Clean'\n",
    "    # Create a directory if it doesn't exist\n",
    "    if not os.path.exists(myCorpusRootClean):\n",
    "        os.makedirs(myCorpusRootClean) \n",
    "    filteredFiles = 0\n",
    "    \n",
    "    for root,dirs,files in os.walk(myCorpusRoot):\n",
    "        for f in files:\n",
    "            fileRoot = os.path.join(root,f)\n",
    "            filename = f\n",
    "            fileOpen = open(fileRoot,\"rt\")\n",
    "            fileText = fileOpen.read()\n",
    "            fileTextCount = countWords(fileText,patterns, tokens)\n",
    "            fileTextCount2 = countWords(fileText,patterns,covid_tokens)\n",
    "            if filename[0:6] in year_month:\n",
    "                if(fileTextCount > 0 and fileTextCount2 > 2):\n",
    "                    filteredFiles = filteredFiles + 1\n",
    "                    copyfile(fileRoot,str(myCorpusRootClean)+'/'+str(filename))\n",
    "                    \n",
    "    print('Copied', filteredFiles, 'to the new directory for the country', country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CN ...\n",
      "Copied 1192 to the new directory for the country CN\n",
      "Processing IR ...\n",
      "Copied 1328 to the new directory for the country IR\n",
      "Processing QA ...\n",
      "Copied 575 to the new directory for the country QA\n",
      "Processing RU ...\n",
      "Copied 1069 to the new directory for the country RU\n",
      "Processing TR ...\n",
      "Copied 428 to the new directory for the country TR\n",
      "Processing US ...\n",
      "Copied 3752 to the new directory for the country US\n",
      "Processing UK ...\n",
      "Copied 2737 to the new directory for the country UK\n",
      "Processing DE ...\n",
      "Copied 255 to the new directory for the country DE\n",
      "Processing FR ...\n",
      "Copied 601 to the new directory for the country FR\n",
      "Processing AE ...\n",
      "Copied 966 to the new directory for the country AE\n",
      "Processing SA ...\n",
      "Copied 548 to the new directory for the country SA\n",
      "Processing KW ...\n",
      "Copied 61 to the new directory for the country KW\n"
     ]
    }
   ],
   "source": [
    "for country in countries:\n",
    "    cleanOnWordCount(country, tokens, covid_tokens, root, patterns, year_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization and stemming the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textClean(text,root,patterns):\n",
    "    text = text.lower() # Text normalization: make string lowercase\n",
    "    s_stemmer = SnowballStemmer(language='english')\n",
    "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text, flags=re.MULTILINE) #Remove URLs\n",
    "    text = html.unescape(text)   #Remove HTML tags\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "    for (pattern, repl) in patterns:\n",
    "        text = re.sub(pattern, repl, text)    #Replace contractions\n",
    "    text = re.sub(r'[^\\w\\s]','', text) # Text normalization: remove punctuation\n",
    "    \n",
    "    words = text.split() # Split string into array of words\n",
    "    for word in words:\n",
    "        word = s_stemmer.stem(word)\n",
    "    cleantext = ' '.join(words)\n",
    "    \n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCountryDataFrame(country, covid_tokens, root, patterns):\n",
    "    print(\"Working...\")\n",
    "    myCorpusRootClean = str(root) + str(country) + 'Clean'\n",
    "    filteredFiles = 0\n",
    "    dfList = []\n",
    "    \n",
    "    for root,dirs,files in os.walk(myCorpusRootClean):\n",
    "        for f in files:\n",
    "            dfListLib = {}\n",
    "            fileRoot = os.path.join(root,f)\n",
    "            filename = f\n",
    "            t = filename[11:]\n",
    "            name_regex = re.compile(r'_[a-z]+',re.RegexFlag.IGNORECASE)\n",
    "            matches = name_regex.findall(t)\n",
    "            if matches != []:\n",
    "                network = matches[0]\n",
    "                network = network.replace('_','')\n",
    "\n",
    "            fileOpen = open(fileRoot,\"rt\")\n",
    "            fileText = fileOpen.read()\n",
    "            \n",
    "            cleanText = textClean(fileText, fileRoot, patterns)\n",
    "            \n",
    "            fileTextCount = countWords(fileText,patterns,covid_tokens)\n",
    "            if fileTextCount > 1:\n",
    "                dfListLib['name'] = filename\n",
    "                dfListLib['path'] = fileRoot\n",
    "                dfListLib['country'] = country\n",
    "                dfListLib['network'] = network\n",
    "                dfListLib['date'] = filename[0:8]\n",
    "                dfListLib['token_freq'] = fileTextCount\n",
    "                dfListLib['text'] = cleanText\n",
    "                dfList.append(dfListLib)\n",
    "    print(country + ' dataframe created!')\n",
    "    return dfList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working...\n",
      "CN dataframe created!\n",
      "Working...\n",
      "IR dataframe created!\n",
      "Working...\n",
      "QA dataframe created!\n",
      "Working...\n",
      "RU dataframe created!\n",
      "Working...\n",
      "TR dataframe created!\n",
      "Working...\n",
      "SA dataframe created!\n",
      "Working...\n",
      "US dataframe created!\n",
      "Working...\n",
      "UK dataframe created!\n",
      "Working...\n",
      "DE dataframe created!\n",
      "Working...\n",
      "FR dataframe created!\n",
      "Working...\n",
      "AE dataframe created!\n",
      "Working...\n",
      "KW dataframe created!\n"
     ]
    }
   ],
   "source": [
    "dfCN = pd.DataFrame(getCountryDataFrame('CN', covid_token2, root, patterns))\n",
    "dfIR = pd.DataFrame(getCountryDataFrame('IR', covid_token2, root, patterns))\n",
    "dfQA = pd.DataFrame(getCountryDataFrame('QA', covid_token2, root, patterns))\n",
    "dfRU = pd.DataFrame(getCountryDataFrame('RU', covid_token2, root, patterns))\n",
    "dfTR = pd.DataFrame(getCountryDataFrame('TR', covid_token2, root, patterns))\n",
    "dfSA = pd.DataFrame(getCountryDataFrame('SA', covid_token2, root, patterns))\n",
    "dfUS = pd.DataFrame(getCountryDataFrame('US', covid_token2, root, patterns))\n",
    "dfUK = pd.DataFrame(getCountryDataFrame('UK', covid_token2, root, patterns))\n",
    "dfDE = pd.DataFrame(getCountryDataFrame('DE', covid_token2, root, patterns))\n",
    "dfFR = pd.DataFrame(getCountryDataFrame('FR', covid_token2, root, patterns))\n",
    "dfAE = pd.DataFrame(getCountryDataFrame('AE', covid_token2, root, patterns))\n",
    "dfKW = pd.DataFrame(getCountryDataFrame('KW', covid_token2, root, patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [dfCN, dfIR, dfQA, dfRU, dfTR, dfSA, dfUS, dfUK, dfDE, dfFR, dfAE, dfKW]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('covid_clean_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>country</th>\n",
       "      <th>network</th>\n",
       "      <th>date</th>\n",
       "      <th>token_freq</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20191201_FR_RFI_GDELT260769.txt</td>\n",
       "      <td>Raw text/FRClean/20191201_FR_RFI_GDELT260769.txt</td>\n",
       "      <td>FR</td>\n",
       "      <td>RFI</td>\n",
       "      <td>20191201</td>\n",
       "      <td>4</td>\n",
       "      <td>an hivaids awareness campaign on the eve of wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20191204_AE_KhaleejTimes_GDELT75493.txt</td>\n",
       "      <td>Raw text/AEClean/20191204_AE_KhaleejTimes_GDEL...</td>\n",
       "      <td>AE</td>\n",
       "      <td>KhaleejTimes</td>\n",
       "      <td>20191204</td>\n",
       "      <td>16</td>\n",
       "      <td>wknd inspired living kt home videos interactiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20191214_TR_AnadoluAgency_NEXIS720304.txt</td>\n",
       "      <td>Raw text/TRClean/20191214_TR_AnadoluAgency_NEX...</td>\n",
       "      <td>TR</td>\n",
       "      <td>AnadoluAgency</td>\n",
       "      <td>20191214</td>\n",
       "      <td>4</td>\n",
       "      <td>virus transmitted to people from wild animals ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20191218_US_USAToday_GNAPI57390.txt</td>\n",
       "      <td>Raw text/USClean/20191218_US_USAToday_GNAPI573...</td>\n",
       "      <td>US</td>\n",
       "      <td>USAToday</td>\n",
       "      <td>20191218</td>\n",
       "      <td>7</td>\n",
       "      <td>alabama mobile researchers from the university...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20191218_US_TheNewHumanitarian_GNAPI57383.txt</td>\n",
       "      <td>Raw text/USClean/20191218_US_TheNewHumanitaria...</td>\n",
       "      <td>US</td>\n",
       "      <td>TheNewHumanitarian</td>\n",
       "      <td>20191218</td>\n",
       "      <td>4</td>\n",
       "      <td>the humanitarian sector has a trust problem th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13426</th>\n",
       "      <td>20200819_GB_DailyMail_NEXIS322650.txt</td>\n",
       "      <td>Raw text/UKClean/20200819_GB_DailyMail_NEXIS32...</td>\n",
       "      <td>UK</td>\n",
       "      <td>DailyMail</td>\n",
       "      <td>20200819</td>\n",
       "      <td>16</td>\n",
       "      <td>jill biden shrugged of president trump is atta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13427</th>\n",
       "      <td>20200819_KW_KUNA_GDELT162457.txt</td>\n",
       "      <td>Raw text/KWClean/20200819_KW_KUNA_GDELT162457.txt</td>\n",
       "      <td>KW</td>\n",
       "      <td>KUNA</td>\n",
       "      <td>20200819</td>\n",
       "      <td>6</td>\n",
       "      <td>loc23272027 gmt kuwait april 23 kuna un secret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13428</th>\n",
       "      <td>20200819_KW_KUNA_GDELT169766.txt</td>\n",
       "      <td>Raw text/KWClean/20200819_KW_KUNA_GDELT169766.txt</td>\n",
       "      <td>KW</td>\n",
       "      <td>KUNA</td>\n",
       "      <td>20200819</td>\n",
       "      <td>3</td>\n",
       "      <td>loc15121212 gmt rome april 26 kuna the kuwaiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13429</th>\n",
       "      <td>20200819_KW_KUNA_GDELT174322.txt</td>\n",
       "      <td>Raw text/KWClean/20200819_KW_KUNA_GDELT174322.txt</td>\n",
       "      <td>KW</td>\n",
       "      <td>KUNA</td>\n",
       "      <td>20200819</td>\n",
       "      <td>5</td>\n",
       "      <td>loc02532353 gmt kuwait march 6 kuna the kuwait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13430</th>\n",
       "      <td>20200820_GB_DailyMail_NEXIS322648.txt</td>\n",
       "      <td>Raw text/UKClean/20200820_GB_DailyMail_NEXIS32...</td>\n",
       "      <td>UK</td>\n",
       "      <td>DailyMail</td>\n",
       "      <td>20200820</td>\n",
       "      <td>10</td>\n",
       "      <td>19million fewer women used contraceptive servi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13431 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                    20191201_FR_RFI_GDELT260769.txt   \n",
       "1            20191204_AE_KhaleejTimes_GDELT75493.txt   \n",
       "2          20191214_TR_AnadoluAgency_NEXIS720304.txt   \n",
       "3                20191218_US_USAToday_GNAPI57390.txt   \n",
       "4      20191218_US_TheNewHumanitarian_GNAPI57383.txt   \n",
       "...                                              ...   \n",
       "13426          20200819_GB_DailyMail_NEXIS322650.txt   \n",
       "13427               20200819_KW_KUNA_GDELT162457.txt   \n",
       "13428               20200819_KW_KUNA_GDELT169766.txt   \n",
       "13429               20200819_KW_KUNA_GDELT174322.txt   \n",
       "13430          20200820_GB_DailyMail_NEXIS322648.txt   \n",
       "\n",
       "                                                    path country  \\\n",
       "0       Raw text/FRClean/20191201_FR_RFI_GDELT260769.txt      FR   \n",
       "1      Raw text/AEClean/20191204_AE_KhaleejTimes_GDEL...      AE   \n",
       "2      Raw text/TRClean/20191214_TR_AnadoluAgency_NEX...      TR   \n",
       "3      Raw text/USClean/20191218_US_USAToday_GNAPI573...      US   \n",
       "4      Raw text/USClean/20191218_US_TheNewHumanitaria...      US   \n",
       "...                                                  ...     ...   \n",
       "13426  Raw text/UKClean/20200819_GB_DailyMail_NEXIS32...      UK   \n",
       "13427  Raw text/KWClean/20200819_KW_KUNA_GDELT162457.txt      KW   \n",
       "13428  Raw text/KWClean/20200819_KW_KUNA_GDELT169766.txt      KW   \n",
       "13429  Raw text/KWClean/20200819_KW_KUNA_GDELT174322.txt      KW   \n",
       "13430  Raw text/UKClean/20200820_GB_DailyMail_NEXIS32...      UK   \n",
       "\n",
       "                  network      date  token_freq  \\\n",
       "0                     RFI  20191201           4   \n",
       "1            KhaleejTimes  20191204          16   \n",
       "2           AnadoluAgency  20191214           4   \n",
       "3                USAToday  20191218           7   \n",
       "4      TheNewHumanitarian  20191218           4   \n",
       "...                   ...       ...         ...   \n",
       "13426           DailyMail  20200819          16   \n",
       "13427                KUNA  20200819           6   \n",
       "13428                KUNA  20200819           3   \n",
       "13429                KUNA  20200819           5   \n",
       "13430           DailyMail  20200820          10   \n",
       "\n",
       "                                                    text  \n",
       "0      an hivaids awareness campaign on the eve of wo...  \n",
       "1      wknd inspired living kt home videos interactiv...  \n",
       "2      virus transmitted to people from wild animals ...  \n",
       "3      alabama mobile researchers from the university...  \n",
       "4      the humanitarian sector has a trust problem th...  \n",
       "...                                                  ...  \n",
       "13426  jill biden shrugged of president trump is atta...  \n",
       "13427  loc23272027 gmt kuwait april 23 kuna un secret...  \n",
       "13428  loc15121212 gmt rome april 26 kuna the kuwaiti...  \n",
       "13429  loc02532353 gmt kuwait march 6 kuna the kuwait...  \n",
       "13430  19million fewer women used contraceptive servi...  \n",
       "\n",
       "[13431 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
     }
   ],
   "source": [
    "ordered_df = df.sort_values(by=\"date\")\n",
    "ordered_df.reset_index(drop=True, inplace=True) #Reset the index\n",
    "ordered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_df.to_csv('covid_cleandf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
